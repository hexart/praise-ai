# AI 情感陪伴聊天应用 - 环境变量配置模板
# 复制此文件为 .env.local 并填入实际的配置值

# ===== Ollama 配置 =====
# 本地 Ollama 服务地址（如果使用本地模型）
# 注意：GitHub Pages 等静态部署无法访问本地服务
VITE_OLLAMA_URL=http://localhost:8000

# ===== OpenAI 配置 =====
# OpenAI API 服务地址
VITE_OPENAI_URL=https://api.openai.com/v1

# OpenAI API 密钥（从 https://platform.openai.com/api-keys 获取）
# 示例格式：sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
VITE_OPENAI_KEY=your-actual-openai-api-key

# ===== Anthropic Claude 配置 =====
# Anthropic API 服务地址
VITE_CLAUDE_URL=https://api.anthropic.com/v1

# Anthropic API 密钥（从 https://console.anthropic.com/ 获取）
# 示例格式：sk-ant-api03-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
VITE_CLAUDE_KEY=your-actual-anthropic-api-key

# ===== 配置说明 =====
# 
# 1. 您可以选择配置其中一个或多个 AI 服务提供商
# 2. 对于 GitHub Pages 等静态部署，无法使用本地 Ollama 服务
# 3. API 密钥请从对应服务商官网获取：
#    - OpenAI: https://platform.openai.com/api-keys
#    - Anthropic: https://console.anthropic.com/
# 4. 请妥善保管您的 API 密钥，不要提交到版本控制系统
# 5. 在部署平台（如 Vercel、Netlify）设置环境变量时，使用相同的变量名

# ===== GitHub Pages 部署注意事项 =====
#
# GitHub Pages 是静态部署，无法使用服务器端环境变量
# 您需要在客户端应用设置界面中手动配置 AI 服务提供商
# 建议配置 OpenAI 或 Claude 等云端服务，无法使用本地 Ollama